{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9d503b07-348b-4042-b568-4528d5965ff4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6513e49-b1cc-4604-b563-cf8b1809fc6a",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td width=15%><img src=\"../../img/UGA.png\"></img></td>\n",
    "<td><center><h1>Project n°3</h1></center></td>\n",
    "<td width=15%><a href=\"https://team.inria.fr/tripop/team-members/\" style=\"font-size: 16px; font-weight: bold\">Florian Vincent</a> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20647865-8316-4ee0-a021-ed961be14b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6901f496-9a78-4b60-a931-303320d3c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca73c79-e5cb-49cf-bafa-6e2496d4e1e5",
   "metadata": {},
   "source": [
    "# Learning text classification\n",
    "\n",
    "This project is heavily inspired from [Jigsaw's *Toxic Comments Classification* challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview) on kaggle.\n",
    "To avoid copy-pastings of foreign code, it will guide you towards specific tools to test and use.\n",
    "\n",
    "## Overview of the project\n",
    "\n",
    "Take a look at the *zip*ed csv data files by unzipping them (`for name in $(ls *.zip); do unzip $name; done;`).\n",
    "\n",
    "Every comment in the train set is classified with a label in `{\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity hate\"}`.\n",
    "You will need to train multiple kind of models to identify those comments, and you will test them against the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0d2de-b876-4cc1-a4e0-56f815616a9b",
   "metadata": {},
   "source": [
    "# Début du projet\n",
    "\n",
    "Dans cette section, nous chargeons les fichiers de données CSV contenant les commentaires et leurs étiquettes associées. Ces données sont divisées en trois parties :\n",
    "- **Entraînement** : Les commentaires avec leurs labels pour entraîner le modèle.\n",
    "- **Test** : Les commentaires sans labels pour l'évaluation.\n",
    "- **Labels de test** : Les étiquettes correspondantes aux données de test, utilisées pour évaluer la performance du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281289d0-29d7-41a9-999e-9b168e200de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d264c746-9ca0-4cac-a096-6d31e66fd241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recherches de valeurs manquantes\n",
    "data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9d034-79f0-46d6-9f77-a12fd665deee",
   "metadata": {},
   "source": [
    "* # Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbc51b5-c426-4733-b6e3-0c3f5e7fb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93417bb-d06a-402a-9b93-4354b312666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de la ponctuation et des sauts de lignes\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_text\"].apply(lambda x : re.sub(\"[^a-zA-Z]\", ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d833cc6-8661-4f08-973f-89441162e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en minuscule\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9308a5a7-41a9-4112-927e-c6aae0bab182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>more i can t make any real suggestions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>congratulations from me as well  use the to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww  he matches this background colour i m s...  \n",
       "2  hey man  i m really not trying to edit war  it...  \n",
       "3    more i can t make any real suggestions on im...  \n",
       "4  you  sir  are my hero  any chance you remember...  \n",
       "5     congratulations from me as well  use the to...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0da52ba-9ab5-4a35-9f7b-1505b25d2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation (séparation mot à mot)\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96de6cb5-bc4b-48a0-bffd-528facef801f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[d, aww, he, matches, this, background, colour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[hey, man, i, m, really, not, trying, to, edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[more, i, can, t, make, any, real, suggestions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>[congratulations, from, me, as, well, use, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  [explanation, why, the, edits, made, under, my...  \n",
       "1  [d, aww, he, matches, this, background, colour...  \n",
       "2  [hey, man, i, m, really, not, trying, to, edit...  \n",
       "3  [more, i, can, t, make, any, real, suggestions...  \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...  \n",
       "5  [congratulations, from, me, as, well, use, the...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16bb43f9-6205-4109-9a36-19ab284523eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des stopwords (mots de \"liaisons\" inutiles)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ac38bb-4147-43df-91dd-7c5b4b59ce84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[aww, matches, background, colour, seemingly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>[congratulations, well, use, tools, well, talk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [aww, matches, background, colour, seemingly, ...  \n",
       "2  [hey, man, really, trying, edit, war, guy, con...  \n",
       "3  [make, real, suggestions, improvement, wondere...  \n",
       "4                [sir, hero, chance, remember, page]  \n",
       "5    [congratulations, well, use, tools, well, talk]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e51ce8-0544-485f-b9be-cc3ddefc69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatisation\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f73eb39-9765-4a5a-990b-b5bde62a2f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[make, real, suggestion, improvement, wondered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>[congratulation, well, use, tool, well, talk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [aww, match, background, colour, seemingly, st...  \n",
       "2  [hey, man, really, trying, edit, war, guy, con...  \n",
       "3  [make, real, suggestion, improvement, wondered...  \n",
       "4                [sir, hero, chance, remember, page]  \n",
       "5      [congratulation, well, use, tool, well, talk]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b368e84f-7803-42a0-80c4-805f77a79e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconversion des listes en chaines de charactères\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4481bf31-345d-4104-a73d-42291cb40c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>congratulation well use tool well talk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  aww match background colour seemingly stuck th...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestion improvement wondered sect...  \n",
       "4                      sir hero chance remember page  \n",
       "5             congratulation well use tool well talk  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bb327-c1c8-4347-83fd-9e53287575a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyage(df) :\n",
    "    # Suppression de la ponctuation et des sauts de lignes\n",
    "    df[\"comment_clean\"] = df[\"comment_text\"].apply(lambda x : re.sub(\"[^a-zA-Z]\", ' ', x))\n",
    "\n",
    "    # Conversion en minuscule\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].str.lower()\n",
    "\n",
    "    # Tokenisation (séparation mot à mot)\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(word_tokenize)\n",
    "\n",
    "    # Suppression des stopwords (mots de \"liaisons\" inutiles)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "    # Reconversion des listes en chaines de charactères\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Attention : la colonne de texte à traiter doit impérativement s'appeler \"comment_text\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bad6c4-2af8-4574-85d5-8011a04cef5c",
   "metadata": {},
   "source": [
    "* # Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11775d-68dc-464a-9758-8134b4dc311c",
   "metadata": {},
   "source": [
    "## Study the data\n",
    "\n",
    "Representing textual data in an algebraic format (i.e. vectors & matrices) is not easy, but fortunately it has been quickly studied earlier in the lectures.\n",
    "\n",
    "**Implement a word-vectorizer relying on simple counting for the textual data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400fe107-4089-43a1-8c60-c7915a9f1cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 158769)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = train[\"comment_clean\"]\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "# Fit and transform the documents into a word count matrix\n",
    "X = vectorizer.fit_transform(documents)\n",
    "print(\"Shape of sparse matrix:\", X.shape)  # Dimensions : nombre de documents × nombre de mots uniques\n",
    "print(\"Vocabulary:\\n\", vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa7031a-2447-4d0e-995e-29de307b9fb8",
   "metadata": {},
   "source": [
    "**Implement another vectorizing relying this time on the *tf-idf* metric. Use a pipeline if needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54080c85-6342-4465-805f-c6baf8e22232",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Charger les documents\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Initialiser TfidfVectorizer avec réduction de vocabulaire\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#min_df=2 signifie que seuls les mots apparaissant dans au moins 2 documents seront inclus.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#max_df=0.8 signifie que les mots présents dans plus de 80% des documents seront ignorés.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#La méthode TF-IDF attribue un poids à chaque mot en fonction de sa fréquence dans un document et de son importance dans l'ensemble du corpus. \n",
    "# dans l'ensemble du corpus, ce qui permet de réduire l'impact des mots très fréquents comme le , est ...\n",
    "# Initialiser TfidfVectorizer avec réduction de vocabulaire\n",
    "#min_df=2 signifie que seuls les mots apparaissant dans au moins 2 documents seront inclus.\n",
    "#max_df=0.9 signifie que les mots présents dans plus de 80% des documents seront ignorés.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Charger les documents\n",
    "documents = train[\"comment_clean\"]\n",
    "\n",
    "# Initialiser TfidfVectorizer avec réduction de vocabulaire\n",
    "#min_df=2 signifie que seuls les mots apparaissant dans au moins 2 documents seront inclus.\n",
    "#max_df=0.8 signifie que les mots présents dans plus de 80% des documents seront ignorés.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=2, max_df=0.9)\n",
    "\n",
    "# Transformer en matrice TF-IDF\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Résumé de la matrice\n",
    "print(\"Shape of sparse matrix (TF-IDF):\", X_tfidf.shape)\n",
    "print(\"Feature names (vocabulary example):\", tfidf_vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Choisir le 3eme commentaire pour inspection\n",
    "first_comment_tfidf = X_tfidf[2].toarray()[0]\n",
    "\n",
    "# Obtenir le vocabulaire (features)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Créer une liste des mots et de leurs poids TF-IDF (non nuls uniquement)\n",
    "non_zero_indices = first_comment_tfidf.nonzero()[0]\n",
    "words_weights = [(feature_names[i], first_comment_tfidf[i]) for i in non_zero_indices]\n",
    "\n",
    "# Trier les mots par ordre décroissant de poids\n",
    "words_weights_sorted = sorted(words_weights, key=lambda x: x[1], reverse=True)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=2, max_df=0.9)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"\\nWords and their TF-IDF weights for the first comment:\")\n",
    "for word, weight in words_weights_sorted:\n",
    "    print(f\"{word}: {weight}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e9bc7-c068-461c-b6d8-1bf2cf121ac6",
   "metadata": {},
   "source": [
    "One may wish to take a deeper look in the database by using various techniques.\n",
    "\n",
    "**Find a suitable dimension reduction technique to study the structure of the data. Display your findings with visual means (you can use `seaborn`).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1c7fd-0bf4-4f69-b1fe-d42535c428db",
   "metadata": {},
   "source": [
    "L'ACP classique, telle qu'implémentée dans sklearn.decomposition.PCA, nécessite que la matrice de données soit dense. Cela implique que, pour les matrices sparse (creuses, contenant majoritairement des zéros), une conversion en matrice dense est nécessaire avant de pouvoir effectuer l'ACP, ce qui peut entraîner une consommation excessive de mémoire.\n",
    "\n",
    "En revanche, TruncatedSVD est spécifiquement conçu pour traiter directement les matrices sparse, telles que celles générées par les représentations TF-IDF en NLP. Cela permet d'économiser une quantité significative d'espace mémoire en évitant toute conversion inutile.\n",
    "\n",
    "Par ailleurs, l'ACP classique repose sur une décomposition complète des matrices, via une méthode connue sous le nom de décomposition en valeurs propres (eigendecomposition). Cette approche est particulièrement coûteuse en temps pour des matrices de grande taille et consomme une quantité importante de mémoire.\n",
    "\n",
    "À l'inverse, TruncatedSVD utilise une technique appelée décomposition SVD tronquée, qui calcule uniquement les premiers n composants principaux sans générer l'intégralité de la matrice de covariance. Cela rend TruncatedSVD non seulement plus rapide, mais également bien plus efficace pour manipuler des matrices de grande dimension, tout en réduisant le coût computationnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed387a-a14b-49c8-b069-3ef33d7a539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de dimensions\n",
    "# Réduction de dimension avec TruncatedSVD (adapté pour matrice sparse pour économiser de l'espace en mémoire) car PCA prend beaucoup de temps à s'executer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)  # Réduction à 2 dimensions pour visualisation\n",
    "X_svd = svd.fit_transform(X_tfidf)  # Pas besoin de convertir en dense\n",
    "\n",
    "# Charger les étiquettes \n",
    "labels = train[\"toxic\"]\n",
    "\n",
    "# Créer un DataFrame pour combiner les composantes SVD et les étiquettes\n",
    "svd_df = pd.DataFrame(data=X_svd, columns=[\"SVD1\", \"SVD2\"])\n",
    "svd_df[\"Label\"] = labels\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x=\"SVD1\", y=\"SVD2\", hue=\"Label\", data=svd_df, palette=\"viridis\", alpha=0.6\n",
    ")\n",
    "plt.title(\"TruncatedSVD Visualization of Text Data\")\n",
    "plt.xlabel(\"SVD Component 1\")\n",
    "plt.ylabel(\"SVD Component 2\")\n",
    "plt.legend(title=\"Label\")\n",
    "plt.show()\n",
    "#La majorité des points (documents) se situent dans une région dense autour des coordonnées proches de (0.2, 0.2).\n",
    "# Les données sont bien projetées sur deux dimensions, ce qui permet une interprétation visuelle.\n",
    "#Les points en bleu (label 0) sont largement dominants dans les données, ce qui indique un déséquilibre des classes (beaucoup plus de textes non toxiques que toxiques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca17720-5d5d-4739-84ae-e6594c2f2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérifiez le ratio entre les classes 0 et 1 pour confirmer le déséquilibre.\n",
    "#Ce déséquilibre  pour toxic n'est pas dû à SVD, mais aux proportions intrinsèques des données.\n",
    "#SVD ne favorise pas une classe ou une autre ; il se concentre uniquement sur la variance des données.\n",
    "#SVD gère efficacement les matrices creuses de TF-IDF.\n",
    "#SVD conserve des tendances globales dans les données, ce qui est utile pour une analyse exploratoire.\n",
    "print(train[\"toxic\"].value_counts(normalize=True))\n",
    "X_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf0a85a-6978-40dc-b92b-3555cb9a5d1f",
   "metadata": {},
   "source": [
    "# Combien de Dimensions Réduire ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3958fac-539c-4bec-8ed6-639d882a0375",
   "metadata": {},
   "source": [
    "Une bonne pratique consiste à examiner la variance expliquée cumulée pour choisir un nombre optimal de dimensions. En analysant la courbe cumulative de la variance expliquée (avec cumulative_variance), on constate que les 300 premières dimensions couvrent généralement 35% de la variance totale dans des tâches de ce projet NLP. Cela signifie que la majorité des informations pertinentes des données d'origine est maintenue. En choisissant 300 dimensions, couvrant déjà la majorité de la variance expliquée, des valeurs plus élevées risquent d'augmenter le coût computationnel sans apporter de gain significatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93175703-bc67-4adf-a487-6f048fd1746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Ajuster SVD avec plus de composantes pour analyser la variance expliquée\n",
    "svd = TruncatedSVD(n_components=1000, random_state=42)\n",
    "svd.fit(X_tfidf)\n",
    "\n",
    "# Variance expliquée cumulative\n",
    "cumulative_variance = svd.explained_variance_ratio_.cumsum()\n",
    "\n",
    "# Visualisation\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance)\n",
    "plt.axhline(y=0.35, color='r', linestyle='--')  # Ligne pour 35% de variance expliquée\n",
    "plt.xlabel(\"Nombre de dimensions\")\n",
    "plt.ylabel(\"Variance expliquée cumulée\")\n",
    "plt.title(\"Analyse de la Variance Expliquée par TruncatedSVD\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fe89f-041d-40f1-890e-6714258c6169",
   "metadata": {},
   "source": [
    "D'après la figure ci dessous, on peut observer que les premières composantes expliquent la majeure partie de la variance. La variance expliquée diminue rapidement après les premières composantes (effet d'\"écrasement\"). Cela indique qu'on peut probablement réduire de manière significative le nombre de dimensions sans perdre beaucoup d'information. Ce qui accélérera nos calculs après pour les modèles comme SVM par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae5a17-1eef-4842-a7a6-0361c152dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Ajuster SVD avec plus de composantes pour analyser la variance expliquée\n",
    "svd = TruncatedSVD(n_components=1000, random_state=42)\n",
    "svd.fit(X_tfidf)\n",
    "\n",
    "# Variance expliquée par chaque composante\n",
    "explained_variance = svd.explained_variance_ratio_\n",
    "\n",
    "# Visualisation de l'histogramme avec les 300 premières dimensions en rouge\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['red' if i < 300 else 'blue' for i in range(len(explained_variance))]\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, color=colors, edgecolor='black')\n",
    "plt.axvline(x=300, color='green', linestyle='--', label=\"300 Dimensions (Ligne de coupe)\")  # Ligne pour 300 dimensions\n",
    "plt.xlabel(\"Numéro de la composante\")\n",
    "plt.ylabel(\"Variance expliquée\")\n",
    "plt.title(\"Histogramme de la Variance Expliquée par TruncatedSVD\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b47bd-60e8-409b-aac6-9fbbfcf0d7d3",
   "metadata": {},
   "source": [
    "## Make classification\n",
    "\n",
    "We will study during this project a small amount of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba356e15-9be9-4556-8666-f92db4d1ce09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c175ff-cbdf-43b5-8478-475c3dd9901f",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "The logistic regression is the most simple and naïve model one can use for classification specifically, but it can provide good insights on the baseline one may wish to achieve with more complex models.\n",
    "\n",
    "**Implement a logistic classifier. Justify every parameter that you choose and how you chose it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2021f4e-441d-453d-bd1e-cad64ae96ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17830d6a-ccf5-4ccc-af00-f1515517265c",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "The support vector machine used to be the SOTA method for many tasks before neural networks became more popular among data scientists.\n",
    "Is has a lot of advantages as compared to logistic regression, as it is a kernel method of which the results are still relatively easy to interpret.\n",
    "\n",
    "**Implement a SVM classifier, justifying your choices of hyper-parameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d2fa00-23bd-44d4-8f96-09179b856cd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Le sous-échantillonnage a été choisi pour travailler avec un volume de données gérable tout en préservant la diversité, ce qui améliore la vitesse d'exécution. La combinaison TF-IDF et SVD a été utilisée pour convertir efficacement les textes en vecteurs numériques et réduire leur dimensionnalité, préparant ainsi les données pour un traitement optimal par le SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268441ad-fc55-4449-b2a7-958c9ba7a625",
   "metadata": {},
   "source": [
    "# Tester que sur 15000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44968ba4-8a1e-4968-b394-4dc188127da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage des lignes invalides dans le test\n",
    "test = test.merge(test_labels, on=\"id\")\n",
    "test = test[test.iloc[:, 2:].sum(axis=1) >= 0]  # Exclure les -1\n",
    "\n",
    "\n",
    "# Limiter le nombre d'observations \n",
    "train = train.sample(n=15000, random_state=42)\n",
    "test = test.sample(n=10000, random_state=42)\n",
    "\n",
    "# Nettoyage des données train et test pour garantir que les données soient cohérentes\n",
    "train = nettoyage(train)\n",
    "test = nettoyage(test)\n",
    "\n",
    "# Initialisation du TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf_train = tfidf_vectorizer.fit_transform(train[\"comment_clean\"])\n",
    "X_tfidf_test = tfidf_vectorizer.transform(test[\"comment_clean\"])\n",
    "\n",
    "# Réduction de dimension avec TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "X_tfidf_train_reduced = svd.fit_transform(X_tfidf_train)\n",
    "X_tfidf_test_reduced = svd.transform(X_tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89976747-4884-461a-a1a6-718313d88581",
   "metadata": {},
   "source": [
    "Pour tester différents paramètres de C, kernel et gamma et choisir les meilleurs, nous pouvons utiliser une validation croisée avec un grid search pour explorer plusieurs combinaisons de ces paramètres. Le GridSearchCV de scikit-learn est parfait pour ce genre d'expérimentation.\n",
    "\n",
    "Après une exécution prolongée de 43 minutes, les résultats obtenus pour la catégorie \"toxic\" par exemple sont prometteurs. La recherche des hyperparamètres a révélé une configuration optimale avec un noyau RBF, une valeur de C à 0.1 et un gamma à 0.1. Cette configuration a permis d'atteindre une précision remarquable de 0.9395 sur l'ensemble de validation, et une accuracy de 0.927 sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f06afa-8f9d-4d0e-beba-7a2266e02488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Catégorie cible\n",
    "category = \"toxic\"\n",
    "\n",
    "# Labels pour la catégorie cible\n",
    "y_train_category = train[category]\n",
    "y_test_category = test[category]\n",
    "\n",
    "# Définir la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],  # Valeurs de régularisation\n",
    "    'kernel': ['linear', 'rbf'],  # Noyaux à tester\n",
    "    'gamma': ['scale', 'auto', 0.1, 1.0]  # Paramètre gamma pour le noyau RBF\n",
    "}\n",
    "\n",
    "# Initialisation du SVM\n",
    "svm_clf = SVC(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Initialisation du GridSearchCV avec validation croisée (par exemple, 5 folds)\n",
    "grid_search = GridSearchCV(estimator=svm_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "grid_search.fit(X_tfidf_train_reduced, y_train_category)\n",
    "\n",
    "# Afficher les meilleurs paramètres et la meilleure précision\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleure précision obtenue : \", grid_search.best_score_)\n",
    "\n",
    "# Utiliser le meilleur modèle pour faire des prédictions sur le test\n",
    "best_svm_clf = grid_search.best_estimator_\n",
    "y_pred_category = best_svm_clf.predict(X_tfidf_test_reduced)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Accuracy sur le test :\", accuracy_score(y_test_category, y_pred_category))\n",
    "print(\"Classification Report sur le test :\\n\", classification_report(y_test_category, y_pred_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb1976-5bba-44ad-a4e0-10f3995530d2",
   "metadata": {},
   "source": [
    "# Sans validation croisée pour la catégorie \"toxic\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811652a8-ed7c-408a-b007-12b585c69e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Catégorie cible\n",
    "category = \"toxic\"\n",
    "\n",
    "# Labels pour la catégorie cible\n",
    "y_train_category = train[category]\n",
    "y_test_category = test[category]\n",
    "\n",
    "# Initialisation et entraînement du modèle SVM: \n",
    "svm_clf = SVC(kernel=\"rbf\", C=0.1,gamma=0.1, class_weight=\"balanced\",random_state=42)\n",
    "svm_clf.fit(X_tfidf_train_reduced, y_train_category)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_category = svm_clf.predict(X_tfidf_test_reduced)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Accuracy:\", accuracy_score(y_test_category, y_pred_category))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_category, y_pred_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff68da9-c0b4-4a6c-aed6-1c1deea19df4",
   "metadata": {},
   "source": [
    " # Avec validation croisée pour la catégorie \"toxic\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb699d13-3159-4d61-a59e-55190eda0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# Catégorie cible\n",
    "category = \"toxic\"\n",
    "\n",
    "# Labels pour la catégorie cible\n",
    "y_train_category = train[category]\n",
    "y_test_category = test[category]\n",
    "\n",
    "svm_clf = SVC(kernel=\"rbf\", C=0.1, gamma=0.1, class_weight=\"balanced\",random_state=42)\n",
    "\n",
    "# Effectuer la validation croisée  avec 5 plis\n",
    "cv_results = cross_validate(svm_clf, X_tfidf_train_reduced, y_train_category, cv=5, scoring='accuracy', return_train_score=False)\n",
    "\n",
    "# Afficher les résultats de la validation croisée\n",
    "print(\"Précision moyenne de la validation croisée : \", cv_results['test_score'].mean())\n",
    "print(\"Scores de précision pour chaque pli : \", cv_results['test_score'])\n",
    "\n",
    "# Initialisation et entraînement final du modèle SVM avec les données d'entraînement\n",
    "svm_clf.fit(X_tfidf_train_reduced, y_train_category)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_category = svm_clf.predict(X_tfidf_test_reduced)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Accuracy sur le test :\", accuracy_score(y_test_category, y_pred_category))\n",
    "print(\"Classification Report sur le test :\\n\", classification_report(y_test_category, y_pred_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d588390-eb86-4c39-bd69-6f0f569ea195",
   "metadata": {},
   "source": [
    "En comparant les résultats avec et sans validation croisée, on constate une précision globale (Accuracy) similaire d'environ 0.904, indiquant que la validation croisée n'a pas engendré de surapprentissage ou sous-apprentissage significatif. Cependant, la classification reste fortement déséquilibrée : la classe majoritaire (0) est très bien prédite (précision 0.90, recall 1.00), tandis que la classe minoritaire (1) est mal détectée (précision 0.96, mais recall seulement 0.02, F1-Score 0.04). Bien que la validation croisée n'améliore pas la performance finale, elle démontre la cohérence du modèle à travers les différents plis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a22ab1-c07c-4cc0-bf2b-914a952f422a",
   "metadata": {},
   "source": [
    "# SVM Avec toutes les catégories :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ea951-cf84-4425-bf3d-c7e6b0925672",
   "metadata": {},
   "source": [
    "Les performances du modèle varient considérablement selon les catégories. Pour \"toxic\" et \"obscene\", les F1-scores de 0.58 et 0.63 respectivement pour la classe 1 sont acceptables, montrant une certaine efficacité dans la détection des classes minoritaires. La catégorie \"insult\" montre également des résultats prometteurs avec un F1-score de 0.56 pour la classe 1, une précision de 0.59 et un rappel de 0.53, ce qui est relativement bon compte tenu du déséquilibre des classes (580 exemples positifs contre 9420 négatifs). Il est important de noter que les accuracy pour toxic, obscene et insult sont respectivement de 0.92, 0.96 et 0.95, ce qui indique une bonne performance globale du modèle pour ces catégories.Cependant, pour \"severe_toxic\", \"threat\", et \"identity_hate\", les performances sont très faibles, avec des précisions et F1-scores extrêmement bas pour les classes 1, malgré parfois un rappel (recall) élevé. Ce problème est principalement dû au déséquilibre important des données, avec moins de 1% d'exemples positifs dans ces catégories, ce qui biaise le modèle SVM vers la classe majoritaire (0) et rend la détection des classes positives très difficile.\n",
    "\n",
    "Enfin, il est à noter que le temps d'exécution pour ce code est d'environ 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31019ad-99f5-4580-970d-99bbef311b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Liste des catégories à tester (par exemple, \"toxic\", \"severe_toxic\", \"obscene\", ...)\n",
    "categories = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# Résultats pour chaque catégorie\n",
    "for category in categories:\n",
    "    print(f\"=== Catégorie : {category} ===\")\n",
    "    \n",
    "    # Labels pour la catégorie cible\n",
    "    y_train_category = train[category]\n",
    "    y_test_category = test[category]\n",
    "    \n",
    "    # Initialisation et entraînement du modèle SVM\n",
    "    svm_clf = SVC(kernel=\"rbf\", C=0.1, gamma=0.1, class_weight=\"balanced\",random_state=42)\n",
    "    svm_clf.fit(X_tfidf_train_reduced, y_train_category)\n",
    "    \n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred_category = svm_clf.predict(X_tfidf_test_reduced)\n",
    "    \n",
    "    # Évaluation des performances\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_category, y_pred_category))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_category, y_pred_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8d911-baf4-48b3-bc36-5db7036ee44e",
   "metadata": {},
   "source": [
    "# Trouver les bons parametres de SVM pour les catégories severe_toxic, threat et identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de66ba-9714-497a-88b7-5889e4c93cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Catégorie cible\n",
    "category = \"threat\"\n",
    "\n",
    "# Labels pour la catégorie cible\n",
    "y_train_category = train[category]\n",
    "y_test_category = test[category]\n",
    "\n",
    "# Définir la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],  # Valeurs de régularisation\n",
    "    'kernel': ['linear', 'rbf'],  # Noyaux à tester\n",
    "    'gamma': ['scale', 'auto', 0.1, 1.0]  # Paramètre gamma pour le noyau RBF\n",
    "}\n",
    "\n",
    "# Initialisation du SVM\n",
    "svm_clf = SVC(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Initialisation du GridSearchCV avec validation croisée (par exemple, 5 folds)\n",
    "grid_search = GridSearchCV(estimator=svm_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "grid_search.fit(X_tfidf_train_reduced, y_train_category)\n",
    "\n",
    "# Afficher les meilleurs paramètres et la meilleure précision\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleure précision obtenue : \", grid_search.best_score_)\n",
    "\n",
    "# Utiliser le meilleur modèle pour faire des prédictions sur le test\n",
    "best_svm_clf = grid_search.best_estimator_\n",
    "y_pred_category = best_svm_clf.predict(X_tfidf_test_reduced)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Accuracy sur le test :\", accuracy_score(y_test_category, y_pred_category))\n",
    "print(\"Classification Report sur le test :\\n\", classification_report(y_test_category, y_pred_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256653b-40f5-4af1-8f5a-eac20c871b61",
   "metadata": {},
   "source": [
    "Apres 32 minutes d'execution , on a trouvé que les meilleures parametres pour SVM pour les catégories threat / identity_hate sont: C: 0.1, gamma: auto, kernel: rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26868a9-ca3e-425e-bf40-cb498505000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégorie cible\n",
    "category = \"identity_hate\"\n",
    "\n",
    "# Labels pour la catégorie cible\n",
    "y_train_category = train[category]\n",
    "y_test_category = test[category]\n",
    "\n",
    "# Définir la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],  # Valeurs de régularisation\n",
    "    'kernel': ['linear', 'rbf'],  # Noyaux à tester\n",
    "    'gamma': ['scale', 'auto', 0.1, 1.0]  # Paramètre gamma pour le noyau RBF\n",
    "}\n",
    "\n",
    "# Initialisation du SVM\n",
    "svm_clf = SVC(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Initialisation du GridSearchCV avec validation croisée (par exemple, 5 folds)\n",
    "grid_search = GridSearchCV(estimator=svm_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "grid_search.fit(X_tfidf_train_reduced, y_train_category)\n",
    "\n",
    "# Afficher les meilleurs paramètres et la meilleure précision\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleure précision obtenue : \", grid_search.best_score_)\n",
    "\n",
    "# Utiliser le meilleur modèle pour faire des prédictions sur le test\n",
    "best_svm_clf = grid_search.best_estimator_\n",
    "y_pred_category = best_svm_clf.predict(X_tfidf_test_reduced)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Accuracy sur le test :\", accuracy_score(y_test_category, y_pred_category))\n",
    "print(\"Classification Report sur le test :\\n\", classification_report(y_test_category, y_pred_category))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da50567-5a94-4b0a-8bd7-a3bca9c4151b",
   "metadata": {},
   "source": [
    "Pour information : le temps d'execution de ce code est environ 20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f5b13-802f-4b1b-b99d-fff62822b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégorie cible\n",
    "category = \"severe_toxic\"\n",
    "\n",
    "# Labels pour la catégorie cible\n",
    "y_train_category = train[category]\n",
    "y_test_category = test[category]\n",
    "\n",
    "# Définir la grille de paramètres à tester\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],  # Valeurs de régularisation\n",
    "    'kernel': ['linear', 'rbf'],  # Noyaux à tester\n",
    "    'gamma': ['scale', 'auto', 0.1, 1.0]  # Paramètre gamma pour le noyau RBF\n",
    "}\n",
    "\n",
    "# Initialisation du SVM\n",
    "svm_clf = SVC(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Initialisation du GridSearchCV avec validation croisée (par exemple, 5 folds)\n",
    "grid_search = GridSearchCV(estimator=svm_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "grid_search.fit(X_tfidf_train_reduced, y_train_category)\n",
    "\n",
    "# Afficher les meilleurs paramètres et la meilleure précision\n",
    "print(\"Meilleurs paramètres : \", grid_search.best_params_)\n",
    "print(\"Meilleure précision obtenue : \", grid_search.best_score_)\n",
    "\n",
    "# Utiliser le meilleur modèle pour faire des prédictions sur le test\n",
    "best_svm_clf = grid_search.best_estimator_\n",
    "y_pred_category = best_svm_clf.predict(X_tfidf_test_reduced)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Accuracy sur le test :\", accuracy_score(y_test_category, y_pred_category))\n",
    "print(\"Classification Report sur le test :\\n\", classification_report(y_test_category, y_pred_category))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31da956-1a84-4ad9-9b0a-0c93fbc748c1",
   "metadata": {},
   "source": [
    "Les résultats pour la catégorie \"severe_toxic\" montrent une accuracy élevée de 0.9789, avec des performances notables dans la détection des cas positifs. Le F1-score pour la classe positive (1) est de 0.27, tandis que le rappel atteint 0.67, indiquant que le modèle identifie 67% des cas \"severe_toxic\". La précision pour cette classe est de 0.17, ce qui signifie que le modèle fait quelques faux positifs tout en détectant efficacement les vrais positifs. Le macro average F1-score de 0.63 reflète une bonne performance globale. Ces résultats démontrent une sensibilité accrue aux cas minoritaires, bien qu'il reste des opportunités d'amélioration. Pour optimiser davantage les performances du modèle, il serait bénéfique d'explorer des techniques supplémentaires pour traiter le déséquilibre des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364ea82-721f-4177-ae7a-4660108c3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégorie cible\n",
    "category = \"severe_toxic\"\n",
    "\n",
    "# Labels pour la catégorie cible\n",
    "y_train_category = train[category]\n",
    "y_test_category = test[category]\n",
    "\n",
    "# Initialisation et entraînement du modèle SVM: \n",
    "svm_clf = SVC(kernel=\"rbf\", C=1.0,gamma=\"scale\", class_weight=\"balanced\",random_state=42)\n",
    "svm_clf.fit(X_tfidf_train_reduced, y_train_category)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_category = svm_clf.predict(X_tfidf_test_reduced)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Accuracy:\", accuracy_score(y_test_category, y_pred_category))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_category, y_pred_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444ab31-38a1-4c39-8fbe-9d9fd27d372e",
   "metadata": {},
   "source": [
    "Les résultats pour les catégories \"threat\" et \"identity_hate\" révèlent des performances très contrastées : Pour \"threat\", l'accuracy est très élevée (0.9966), mais le modèle échoue complètement à identifier les cas positifs. Les scores de précision, rappel et F1-score pour la classe positive sont tous à 0, indiquant que le modèle classe systématiquement tous les exemples comme négatifs. Cela suggère un problème sévère de déséquilibre des classes, avec seulement 34 exemples positifs sur 10000. Pour \"identity_hate\", les résultats sont inhabituels. L'accuracy est extrêmement basse (0.0125), mais le rappel pour la classe positive est de 1.00, signifiant que le modèle identifie tous les cas positifs. Cependant, la précision très faible (0.01) indique que le modèle classe presque tous les exemples comme positifs, résultant en de nombreux faux positifs. Ce comportement pourrait être dû à une sur-correction du déséquilibre des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d46c91-d650-4fdf-b059-edb1fa3496d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"threat\",\"identity_hate\"]\n",
    "\n",
    "# Résultats pour chaque catégorie\n",
    "for category in categories:\n",
    "    print(f\"=== Catégorie : {category} ===\")\n",
    "    \n",
    "    # Labels pour la catégorie cible\n",
    "    y_train_category = train[category]\n",
    "    y_test_category = test[category]\n",
    "    \n",
    "    # Initialisation et entraînement du modèle SVM\n",
    "    svm_clf = SVC(kernel=\"rbf\", C=0.1, gamma=\"auto\", class_weight=\"balanced\",random_state=42)\n",
    "    svm_clf.fit(X_tfidf_train_reduced, y_train_category)\n",
    "    \n",
    "    # Prédiction sur le jeu de test\n",
    "    y_pred_category = svm_clf.predict(X_tfidf_test_reduced)\n",
    "    \n",
    "    # Évaluation des performances\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_category, y_pred_category))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_category, y_pred_category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0669a6e-aa9f-4e01-b3f4-20f11c897b65",
   "metadata": {},
   "source": [
    "## Other models\n",
    "\n",
    "**Choose a model between the following:**\n",
    "* **K-Nearest Neighbors (*KNN*)**\n",
    "* **Decision Tree**\n",
    "* **Random Forest**\n",
    "\n",
    "**Describe IN YOUR OWN WORDS (plagiarism checks will be made if needed) how the method works, and implement it for the current case, discussing its hyperparameters as well.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50325dd-53a0-452c-b586-31a41046e646",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "La méthode de Random Forest se base sur **plusieurs** *arbres de décisions* indépendants afin de prédire un modèle plus précis que ceux obtenu par chaque arbe individuellement.\n",
    "Un arbre de décision est un ensemble d'algorithmes permettant de séparer au mieux nos données selon un certains nombre de décisions, représentées par des *branches*.\n",
    "Un arbre est très sensible aux variation des données d'apprentissage. C'est pour cela qu'une forêt est généralement privilégiée : en combinant les résultats de plusieurs arbres de décisions réalisés sur des données d'apprentissage variables, la forêt aléatoire réduite le risque d'erreurs dû à des changements dans les dites données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "532301e3-6321-4f56-8974-7f1f0411f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test = test[test_labels[\"toxic\"] != -1]\n",
    "\n",
    "test_labels = test_labels[test_labels[\"toxic\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdcfc7-117b-40d0-a963-d7ea9b0ad28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données\n",
    "train = nettoyage(train)\n",
    "test = nettoyage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b3e73-c240-44e9-8e75-94a351bcd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commentaires et cibles\n",
    "X_train = train[\"comment_clean\"]\n",
    "Y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
    "\n",
    "X_test = test[\"comment_clean\"]\n",
    "Y_test = test_labels[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54409c-8e2c-4333-8e75-f7277ddd8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriser\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d76863-c890-42c4-836e-c02fb96d216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de dimensions\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_test_svd = svd.fit_transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433f83c-9c90-413f-9832-ad2a7f12e322",
   "metadata": {},
   "source": [
    "## Compare models\n",
    "\n",
    "One must then compare the models on the test set and provide metrics to study it.\n",
    "\n",
    "**Compare previously studied models, with counting *tf* and *tf-idf* as vectorizers, for their best hyperparameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942f41b-d612-4a77-9395-26fd4600bdcd",
   "metadata": {},
   "source": [
    "## SVM VS LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9553dbb-a7ec-4658-81f0-99df9775c697",
   "metadata": {},
   "source": [
    "En raison des limitations matérielles, j’ai utilisé une sous-partie du dataset (15 000 observations pour l’entraînement et 10 000 pour les tests), contrairement à mes collègues qui ont travaillé sur l’ensemble des données. Cela rend mes résultats avec le SVM difficilement comparables, car le modèle n’a pas été exposé à l’intégralité des données, ce qui pourrait biaiser les métriques obtenues, comme des scores plus élevés sur cet échantillon restreint. Le SVM présente des avantages notables : il est particulièrement performant sur des datasets de taille modérée et des classes déséquilibrées, grâce à l’argument class_weight=\"balanced\", et il modélise des relations complexes via des noyaux comme RBF tout en résistant au surapprentissage. De plus, l’optimisation des hyperparamètres (par GridSearch) a permis d’améliorer ses performances. Cependant, son principal inconvénient réside dans sa scalabilité : son temps d’exécution devient prohibitif sur des datasets volumineux ou très dimensionnels. Pour remédier à cela, il est souvent nécessaire de réduire à la fois le nombre de points (échantillonnage) et les dimensions (via PCA), car réduire uniquement les dimensions ne suffit pas à diminuer significativement le temps d’exécution. En comparaison, la régression logistique est plus rapide, même avec de grands volumes de données, grâce à sa simplicité basée sur des calculs matriciels, ce qui la rend plus adaptée aux très grands datasets tout en offrant des performances compétitives. En conclusion, bien que le SVM soit un excellent choix pour des problèmes complexes ou des datasets modérés, une comparaison équitable avec d’autres modèles, comme la régression logistique, nécessiterait d’évaluer tous les modèles sur l’ensemble des données pour tirer des conclusions définitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c46f7be-3ce9-4671-8a65-e14fb9990dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082f18b-9694-4871-b70b-1270a9d6c3df",
   "metadata": {},
   "source": [
    "Conclusion : \n",
    "La logistic regression = meilleur modèle : même résultats que rf mais bien mieux en terme de temps d'exécution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce94cb-6113-4a0a-920d-8de719ea343b",
   "metadata": {},
   "source": [
    "## Use your model\n",
    "\n",
    "**Use the best model to build a Command-Line Interface (*CLI*) that is launched by the command `./cli.py [options]` using the `argsparse` module, and that accepts in stdin (standard input) english sentences and classifies them, displaying the result and interesting metrics if relevant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd601a3-00c9-409b-b288-dbd4dbc8d418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
