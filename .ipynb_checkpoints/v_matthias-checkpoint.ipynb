{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9d503b07-348b-4042-b568-4528d5965ff4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6513e49-b1cc-4604-b563-cf8b1809fc6a",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td width=15%><img src=\"../../img/UGA.png\"></img></td>\n",
    "<td><center><h1>Project n°3</h1></center></td>\n",
    "<td width=15%><a href=\"https://team.inria.fr/tripop/team-members/\" style=\"font-size: 16px; font-weight: bold\">Florian Vincent</a> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20647865-8316-4ee0-a021-ed961be14b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6901f496-9a78-4b60-a931-303320d3c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca73c79-e5cb-49cf-bafa-6e2496d4e1e5",
   "metadata": {},
   "source": [
    "# Learning text classification\n",
    "\n",
    "This project is heavily inspired from [Jigsaw's *Toxic Comments Classification* challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview) on kaggle.\n",
    "To avoid copy-pastings of foreign code, it will guide you towards specific tools to test and use.\n",
    "\n",
    "## Overview of the project\n",
    "\n",
    "Take a look at the *zip*ed csv data files by unzipping them (`for name in $(ls *.zip); do unzip $name; done;`).\n",
    "\n",
    "Every comment in the train set is classified with a label in `{\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity hate\"}`.\n",
    "You will need to train multiple kind of models to identify those comments, and you will test them against the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d63c9-9390-4fb0-9ff8-f1b332ece4f0",
   "metadata": {},
   "source": [
    "## Study the data\n",
    "\n",
    "Representing textual data in an algebraic format (i.e. vectors & matrices) is not easy, but fortunately it has been quickly studied earlier in the lectures.\n",
    "\n",
    "**Implement a word-vectorizer relying on simple counting for the textual data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281289d0-29d7-41a9-999e-9b168e200de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test = test[test_labels[\"toxic\"] != -1]\n",
    "\n",
    "test_labels = test_labels[test_labels[\"toxic\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d264c746-9ca0-4cac-a096-6d31e66fd241",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Recherches de valeurs manquantes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdata_train\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Recherches de valeurs manquantes\n",
    "data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9d034-79f0-46d6-9f77-a12fd665deee",
   "metadata": {},
   "source": [
    "* # Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc51b5-c426-4733-b6e3-0c3f5e7fb822",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93417bb-d06a-402a-9b93-4354b312666f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Suppression de la ponctuation et des sauts de lignes\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_text\"].apply(lambda x : re.sub(\"[^a-zA-Z]\", ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea837601-bdec-404f-8793-535738d8ba65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d833cc6-8661-4f08-973f-89441162e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en minuscule\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9308a5a7-41a9-4112-927e-c6aae0bab182",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_train\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m6\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0da52ba-9ab5-4a35-9f7b-1505b25d2eb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tokenisation (séparation mot à mot)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata_train\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(word_tokenize)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenisation (séparation mot à mot)\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96de6cb5-bc4b-48a0-bffd-528facef801f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[d, aww, he, matches, this, background, colour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[hey, man, i, m, really, not, trying, to, edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[more, i, can, t, make, any, real, suggestions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>[congratulations, from, me, as, well, use, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  [explanation, why, the, edits, made, under, my...  \n",
       "1  [d, aww, he, matches, this, background, colour...  \n",
       "2  [hey, man, i, m, really, not, trying, to, edit...  \n",
       "3  [more, i, can, t, make, any, real, suggestions...  \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...  \n",
       "5  [congratulations, from, me, as, well, use, the...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16bb43f9-6205-4109-9a36-19ab284523eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Suppression des stopwords (mots de \"liaisons\" inutiles)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ac38bb-4147-43df-91dd-7c5b4b59ce84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[aww, matches, background, colour, seemingly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>[congratulations, well, use, tools, well, talk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [aww, matches, background, colour, seemingly, ...  \n",
       "2  [hey, man, really, trying, edit, war, guy, con...  \n",
       "3  [make, real, suggestions, improvement, wondere...  \n",
       "4                [sir, hero, chance, remember, page]  \n",
       "5    [congratulations, well, use, tools, well, talk]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e51ce8-0544-485f-b9be-cc3ddefc69df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatisation\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f73eb39-9765-4a5a-990b-b5bde62a2f5e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[make, real, suggestion, improvement, wondered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>[congratulation, well, use, tool, well, talk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [aww, match, background, colour, seemingly, st...  \n",
       "2  [hey, man, really, trying, edit, war, guy, con...  \n",
       "3  [make, real, suggestion, improvement, wondered...  \n",
       "4                [sir, hero, chance, remember, page]  \n",
       "5      [congratulation, well, use, tool, well, talk]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b368e84f-7803-42a0-80c4-805f77a79e29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reconversion des listes en chaines de charactères\n",
    "data_train[\"comment_clean\"] = data_train[\"comment_clean\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4481bf31-345d-4104-a73d-42291cb40c60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>congratulation well use tool well talk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "\n",
       "                                       comment_clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  aww match background colour seemingly stuck th...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestion improvement wondered sect...  \n",
       "4                      sir hero chance remember page  \n",
       "5             congratulation well use tool well talk  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[[\"comment_text\", \"comment_clean\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4264cd-580f-4806-b160-62a5901c3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06a77c3-b697-469c-a5b5-93d3bf2c5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyage(df) :\n",
    "    # Suppression de la ponctuation et des sauts de lignes\n",
    "    df[\"comment_clean\"] = df[\"comment_text\"].apply(lambda x : re.sub(\"[^a-zA-Z]\", ' ', x))\n",
    "\n",
    "    # Conversion en minuscule\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].str.lower()\n",
    "\n",
    "    # Tokenisation (séparation mot à mot)\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(word_tokenize)\n",
    "\n",
    "    # Suppression des stopwords (mots de \"liaisons\" inutiles)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "    # Reconversion des listes en chaines de charactères\n",
    "    df[\"comment_clean\"] = df[\"comment_clean\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Attention : la colonne de texte à traiter doit impérativement s'appeler \"comment_text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928183f6-c1ca-4610-81fb-359dcf16d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nettoyage(test)\n",
    "train = nettoyage(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bad6c4-2af8-4574-85d5-8011a04cef5c",
   "metadata": {},
   "source": [
    "* # Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "400fe107-4089-43a1-8c60-c7915a9f1cd3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sparse matrix: (159571, 10000)\n",
      "Vocabulary:\n",
      " ['aa' 'aaron' 'ab' ... 'zoo' 'zuck' 'zuckerberg']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Modèle Sac de Mots (CountVectorizer)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 10000)\n",
    "X_cv = cv.fit_transform(train[\"comment_clean\"])\n",
    "print(\"Shape of sparse matrix:\", X_cv.shape)  # Dimensions : nombre de commentaires × nombre de mots uniques\n",
    "print(\"Vocabulary:\\n\", cv.get_feature_names_out())\n",
    "print(X_cv.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa7031a-2447-4d0e-995e-29de307b9fb8",
   "metadata": {},
   "source": [
    "**Implement another vectorizing relying this time on the *tf-idf* metric. Use a pipeline if needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484f223e-c486-456a-97d9-a144f22459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_df = 0.9)\n",
    "\n",
    "# min_df = 2 signifie que seuls les mots apparaissant dans au moins 2 documents seront inclus.\n",
    "# max_df = 0.9 signifie que les mots présents dans plus de 90% des documents seront ignorés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e9bc7-c068-461c-b6d8-1bf2cf121ac6",
   "metadata": {},
   "source": [
    "One may wish to take a deeper look in the database by using various techniques.\n",
    "\n",
    "**Find a suitable dimension reduction technique to study the structure of the data. Display your findings with visual means (you can use `seaborn`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f206e22-9e27-45f9-987d-fc21a8e1bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components = 300, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c175ff-cbdf-43b5-8478-475c3dd9901f",
   "metadata": {},
   "source": [
    "## Make classification\n",
    "\n",
    "We will study during this project a small amount of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50325dd-53a0-452c-b586-31a41046e646",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "La méthode de Random Forest se base sur **plusieurs** *arbres de décisions* indépendants afin de prédire un modèle plus précis que ceux obtenu par chaque arbe individuellement.\n",
    "Un arbre de décision est un ensemble d'algorithmes permettant de séparer au mieux nos données selon un certains nombre de décisions, représentées par des *branches*.\n",
    "Un arbre est très sensible aux variation des données d'apprentissage. C'est pour cela qu'une forêt est généralement privilégiée : en combinant les résultats de plusieurs arbres de décisions réalisés sur des données d'apprentissage variables, la forêt aléatoire réduite le risque d'erreurs dû à des changements dans les dites données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ccfd4-2a3c-4eb2-9801-edaa5e02c3aa",
   "metadata": {},
   "source": [
    "***Questions :***\n",
    "- combien de lignes utiliser pour chaque arbre ? \n",
    "- Combien d'arbres en tout ?\n",
    "- Traiter toutes les colonnes en même temps ou séparément ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b8cc813-9946-4e60-9646-27d7bacc348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test = test[test_labels[\"toxic\"] != -1]\n",
    "\n",
    "test_labels = test_labels[test_labels[\"toxic\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552fd5e8-d84f-4e75-9fb6-da05e84b038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données\n",
    "train = nettoyage(train)\n",
    "test = nettoyage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5528d346-172e-4cf4-bb82-e1561d04a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables explicatives et cibles\n",
    "X_train = train[\"comment_clean\"]\n",
    "Y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
    "\n",
    "X_test = test[\"comment_clean\"]\n",
    "Y_test = test_labels[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c057a8f7-cf7d-4b77-8831-b277a7e81bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriser\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc36a63-d852-468e-b3a9-5385a70038ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de dimensions\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_test_svd = svd.fit_transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14d8d4a-9fbb-4ba2-ae61-6caea4882e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement simultané\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "# Forêt à 10 arbres\n",
    "rf_10 = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "multi_rf_10 = MultiOutputClassifier(rf_10)\n",
    "# Permet de faire un modèle multi-label, i.e. de prédire plusieurs colonnes à la fois.\n",
    "\n",
    "\n",
    "# Entrainement\n",
    "# multi_rf_10.fit(X_train_svd, Y_train)\n",
    "\n",
    "\n",
    "# Prédiction\n",
    "# Y_pred = multi_rf_10.predict(X_test_svd)\n",
    "\n",
    "# 135 secondes pour n_estimators = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d09f5ef7-c573-4c06-afa7-3f59c07213a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Meilleurs paramètres : {'estimator__max_depth': 50}\n"
     ]
    }
   ],
   "source": [
    "# Recherche des meilleurs hyperparamètres\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(min_samples_leaf = 1, min_samples_split = 6, n_estimators = 10, random_state = 42)\n",
    "multi_rf = MultiOutputClassifier(rf)\n",
    "\n",
    "\n",
    "# Grille des hyperparamètres\n",
    "param_grid = {\n",
    "    # \"estimator__n_estimators\": [5, 10, 20],          # Nombre d'arbres\n",
    "    # \"estimator__min_samples_split\": [4, 6, 8],       # Nombre minimal d'échantillons pour diviser un noeud\n",
    "    # \"estimator__min_samples_leaf\": [1, 2, 3],        # Nombre minimal d'échantillons par feuille\n",
    "    \"estimator__max_depth\": [5, 10, 20, 50, 100]       # Profondeur maximale des arbres\n",
    "}\n",
    "# Les noms des hyperparamètres sont précédés de \"estimator__\" car le modèle est encapsulé dans 'multi_rf'.\n",
    "\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(multi_rf, param_grid, cv = 3, scoring = \"f1_micro\", verbose = 1, n_jobs = -1)\n",
    "# cv : divise le dataset en i et entraîne/teste sur ces différentes combinaisons.\n",
    "# scoring : métrique utilisée pour évaluer le modèle. Ici, \"f1_micro\" est utilisé car multi-label (f1 = métrique de base).\n",
    "# verbose : quantité de détails affichés lors de l'exécution.\n",
    "# n_jobs = -1 : tous les cv sont exécuté en parallèle pour accélérer la recherche.\n",
    "\n",
    "grid_search.fit(X_train_svd, Y_train)\n",
    "\n",
    "\n",
    "# Meilleurs paramètres\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "\n",
    "# 2264 secondes pour trouve les 3 premiers paramètres.\n",
    "# On les fixe donc aux valeurs de sortie (10, 6, 1 resp) et on se concentre ensuite sur max_depth.\n",
    "# Meilleure max_depth = 50 (trouvé en 230 secondes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d74f4ea-f676-449b-a9c3-9d14e67e3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions avec le meilleur modèle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "rf_opt = RandomForestClassifier(min_samples_leaf = 1, \n",
    "                                min_samples_split = 6, \n",
    "                                n_estimators = 10, \n",
    "                                max_depth = 50,\n",
    "                                random_state = 42)\n",
    "multi_rf_opt = MultiOutputClassifier(rf_opt)\n",
    "\n",
    "multi_rf_opt.fit(X_train_svd, Y_train)\n",
    "\n",
    "Y_pred = multi_rf_opt.predict(X_test_svd)\n",
    "\n",
    "# 229 secondes pour faire l'entraînement/prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20844cd7-fce9-474f-9f54-edfcbb536a25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport pour chaque catégorie : \n",
      "\n",
      "\n",
      " \n",
      "Catégorie: toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     57888\n",
      "           1       0.42      0.10      0.16      6090\n",
      "\n",
      "    accuracy                           0.90     63978\n",
      "   macro avg       0.67      0.54      0.55     63978\n",
      "weighted avg       0.87      0.90      0.87     63978\n",
      "\n",
      "         0 prédit  1 prédit\n",
      "0 donné     57052       836\n",
      "1 donné      5487       603\n",
      "\n",
      " \n",
      "Catégorie: severe_toxic\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     63611\n",
      "           1       0.00      0.00      0.00       367\n",
      "\n",
      "    accuracy                           0.99     63978\n",
      "   macro avg       0.50      0.50      0.50     63978\n",
      "weighted avg       0.99      0.99      0.99     63978\n",
      "\n",
      "         0 prédit  1 prédit\n",
      "0 donné     63610         1\n",
      "1 donné       367         0\n",
      "\n",
      " \n",
      "Catégorie: obscene\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     60287\n",
      "           1       0.55      0.12      0.19      3691\n",
      "\n",
      "    accuracy                           0.94     63978\n",
      "   macro avg       0.75      0.56      0.58     63978\n",
      "weighted avg       0.93      0.94      0.93     63978\n",
      "\n",
      "         0 prédit  1 prédit\n",
      "0 donné     59937       350\n",
      "1 donné      3256       435\n",
      "\n",
      " \n",
      "Catégorie: threat\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     63767\n",
      "           1       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           1.00     63978\n",
      "   macro avg       0.50      0.50      0.50     63978\n",
      "weighted avg       0.99      1.00      1.00     63978\n",
      "\n",
      "         0 prédit  1 prédit\n",
      "0 donné     63767         0\n",
      "1 donné       211         0\n",
      "\n",
      " \n",
      "Catégorie: insult\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     60551\n",
      "           1       0.23      0.02      0.03      3427\n",
      "\n",
      "    accuracy                           0.94     63978\n",
      "   macro avg       0.59      0.51      0.50     63978\n",
      "weighted avg       0.91      0.94      0.92     63978\n",
      "\n",
      "         0 prédit  1 prédit\n",
      "0 donné     60371       180\n",
      "1 donné      3374        53\n",
      "\n",
      " \n",
      "Catégorie: identity_hate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     63266\n",
      "           1       0.00      0.00      0.00       712\n",
      "\n",
      "    accuracy                           0.99     63978\n",
      "   macro avg       0.49      0.50      0.50     63978\n",
      "weighted avg       0.98      0.99      0.98     63978\n",
      "\n",
      "         0 prédit  1 prédit\n",
      "0 donné     63262         4\n",
      "1 donné       712         0\n",
      "\n",
      " \n",
      " Précision générale :  0.8858513864140798 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Cellar/jupyterlab/4.3.2_1/libexec/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Évaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Rapport pour chaque catégorie : \\n\")\n",
    "for i, column in enumerate(Y_train.columns):\n",
    "    print(\"\\n \\n\" f\"Catégorie: {column}\")\n",
    "    print(pd.DataFrame(confusion_matrix(Y_test.iloc[:, i], Y_pred[:, i]),\n",
    "             index = [\"0 donné\", \"1 donné\"],\n",
    "             columns = [\"0 prédit\", \"1 prédit\"]))\n",
    "\n",
    "print(\"\\n \\n Précision générale : \", accuracy_score(Y_test, Y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433f83c-9c90-413f-9832-ad2a7f12e322",
   "metadata": {},
   "source": [
    "## Compare models\n",
    "\n",
    "One must then compare the models on the test set and provide metrics to study it.\n",
    "\n",
    "**Compare previously studied models, with counting *tf* and *tf-idf* as vectorizers, for their best hyperparameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c46f7be-3ce9-4671-8a65-e14fb9990dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Label  Precision    Recall  F1-Score  Accuracy\n",
      "0          toxic   0.880646  0.907187  0.879525  0.907187\n",
      "1   severe_toxic   0.989212  0.994154  0.991379  0.994154\n",
      "2        obscene   0.927590  0.944246  0.927719  0.944246\n",
      "3         threat   0.993415  0.996702  0.995056  0.996702\n",
      "4         insult   0.917160  0.945544  0.922510  0.945544\n",
      "5  identity_hate   0.977866  0.988840  0.983322  0.988840\n",
      "\n",
      " \n",
      " Précision générale :  0.8901653693457126 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Résultats multi-rf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "for i, column in enumerate(Y_train.columns):\n",
    "    # Calculer le rapport de classification\n",
    "    report = classification_report(Y_test.iloc[:, i], Y_pred[:, i], \n",
    "                          zero_division = 0,  # Évite les avertissements\n",
    "                          output_dict = True\n",
    "                         )\n",
    "    \n",
    "    # Calculer l'accuracy pour chaque étiquette\n",
    "    accuracy = accuracy_score(Y_test.iloc[:, i], Y_pred[:, i])\n",
    "    \n",
    "    # Ajouter les résultats au tableau\n",
    "    results.append({\n",
    "        \"Label\": column,\n",
    "        \"Precision\": report['weighted avg']['precision'],\n",
    "        \"Recall\": report['weighted avg']['recall'],\n",
    "        \"F1-Score\": report['weighted avg']['f1-score'],\n",
    "        \"Accuracy\": accuracy  # Ajouter l'accuracy à chaque étiquette\n",
    "    })\n",
    "\n",
    "# Afficher les résultats sous forme de tableau\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "print(\"\\n \\n Précision générale : \", accuracy_score(Y_test, Y_pred), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce94cb-6113-4a0a-920d-8de719ea343b",
   "metadata": {},
   "source": [
    "## Use your model\n",
    "\n",
    "**Use the best model to build a Command-Line Interface (*CLI*) that is launched by the command `./cli.py [options]` using the `argsparse` module, and that accepts in stdin (standard input) english sentences and classifies them, displaying the result and interesting metrics if relevant.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
